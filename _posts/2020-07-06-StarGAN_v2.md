---

layout: mypost
title: StarGAN v2
categories: [Paper Reading]

---

# StarGAN v2: Diverse Image Synthesis for Multiple Domains

summarize by Boning Song on 2020.7.6

Code: https://github.com/clovaai/stargan-v2.



## TL; DR 

* starGAN的升级版，a scalable approach that can generate **diverse** images across **multiple domains**，加入了mapping network和style encoder
* 同时解决两个问题
  * diversity of generated images 
  * scalability over multiple domains

![1](./source/sbn-1.png)



## Contribution

1. mapping network和style encoder，可以映射和提取style code
2. 给定一个domain可以生成diversity的图片，比之前的方法更高清多样
3. AFHQ动物脸高清数据集



## method

- 先明确定义：**domain** implies a set of images that can be grouped as a visually distinctive category, and each image has a unique appearance, which we call **style**. For example, we can set image domains based on the gender of a person, in which case the style in- cludes makeup, beard, and hairstyle

- Stargan v1的问题： learns a deterministic mapping per each domain，给定一个输入和一个label只能得到确定的一个输出

  ![](./source/sbn-6.png)

- 问题：`\(\mathcal{X}\)`：images，`\(\mathcal{Y}\)`：possible domains，`\(\mathbf{x} \in \mathcal{X}, y \in \mathcal{Y}\)`

- 模型：

  - generator：`\(G(\mathbf{x}, \mathbf{s})\)`，使用AdaIN模块
  - mapping network：`\(\mathbf{s} = F_y(\mathbf{z})\)`，每个domain有个输出
  - style encoder：`\(s = E_y(\mathbf{x})\)`，每个domain有个输出
  - discriminator：`\(D_y\)`，每个domain有个输出

  ![2](./source/sbn-2.png)

- 训练`\(\min_{G,F,E} \max_D \mathcal{L}_{adv} + \lambda_{sty}\mathcal{L}_{sty} - \lambda_{ds}\mathcal{L}_{ds} + \lambda_{cyc}\mathcal{L}_{cyc}\)`
  - adversarial：`\(\mathcal{L}_{adv} = \mathbb{E}_{\mathbf{x},y}[\log D_{y}(\mathbf{x})] + \mathbb{E}_{\mathbf{x},\tilde{y},\mathbf{z}}[\log(1-D_{\tilde{y}}(G(\mathbf{x},\tilde{\mathbf{s}})))]\)`
  - Style reconstruction：`\(\mathcal{L}_{sty} = \mathbb{E}_{\mathbf{x},\tilde{y},\mathbf{z}}[\|\tilde{\mathbf{s}}-E_{\tilde{y}}(G(\mathbf{x},\tilde{\mathbf{s}}))\|_1]\)`
  - Style diversification：`\(\mathcal{L}_{ds} = \mathbb{E}_{\mathbf{x},\tilde{y},\mathbf{z}_1,\mathbf{z}_2}[\|G(\mathbf{x},\tilde{\mathbf{s}}_1) - G(\mathbf{x},\tilde{\mathbf{s}}_2)\|_1]\)`
  - Preserving source characteristics：`\(\mathcal{L}_{cyc} = \mathbb{E}_{\mathbf{x},y, \tilde{y},\mathbf{z}}[\|\mathbf{x} - G(G(\mathbf{x},\tilde{\mathbf{s}}),\hat{\mathbf{s}}) \|_1]\)`，`\(\hat{\mathbf{s}} = E_y(\mathbf{x})\)`





## Experiments

![3](source/sbn-3.png)

![7](./source/sbn-7.png)

- 消融试验
  - B：FUNIT的discriminator
  - C：Which Training Methods for GANs do actually Converge?
  - D：MUNIT使用z
  - E：使用style code和mapping network
  - F：多一个loss
  - LPIPS：learned perceptual image patch similarity
- reference guided

![4](source/sbn-4.png)

![](./source/sbn-10.png)

![9](./source/sbn-9.png)

- 对比
  - baseline的LPIPS高作者说是因为数据集牛批

![5](source/sbn-5.png)

![8](./source/sbn-8.png)

## Thoughts

- Multi domain transfer

